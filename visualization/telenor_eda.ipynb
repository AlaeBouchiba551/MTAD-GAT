{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring The Telenor Telco Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import os\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import plotly as py\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode\n",
    "import plotly.graph_objs as go\n",
    "import seaborn as sns\n",
    "import cufflinks as cf\n",
    "import glob\n",
    "import sys\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "cf.go_offline()\n",
    "init_notebook_mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../../Data/Data_DK/radio_kpis_sample.csv'\n",
    "#data_path = '../../Hackathon2021_Telenor/hackathon_kpis_anonymised.csv'\n",
    "df = pd.read_csv(data_path, sep=\";\")\n",
    "df_orig = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some info\n",
    "From below we see that we have 1048575 rows of data, each with 24 columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print number of nans for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nan_values = df.isna().sum()\n",
    "print(nan_values)\n",
    "nan_columns = nan_values[nan_values > 0].index.tolist()\n",
    "nan_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[df['tech'] == '2G']\n",
    "nan_values = df2.isna().sum()\n",
    "nan_values / df2.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[df['tech'] == '3G']\n",
    "nan_values = df2.isna().sum()\n",
    "nan_values / df2.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[df['tech'] == '4G']\n",
    "nan_values = df2.isna().sum()\n",
    "nan_values / df2.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing data for a TEST cell \n",
    "df = df[df['cell_name'] != 'J5002D11_TEST']\n",
    "\n",
    "# Remove 2G cells (for now)\n",
    "df = df[df['tech'] != '2G']\n",
    "\n",
    "# Some rows have columns with values -1, removing those rows\n",
    "# columns with some -1 values:\n",
    "# mcdr_nom_s, msdr_nom_s, msdr_nom_d, ho_nom\n",
    "for c in ['mcdr_nom_s', 'msdr_nom_s', 'msdr_nom_d', 'ho_nom']:\n",
    "    df = df[df[c] != -1]\n",
    "\n",
    "# Converting a OBJECT column to FLOAT\n",
    "df['thp_nom_tt_kpi'].replace('0,00E+00', 0.0, inplace=True)\n",
    "df['thp_denom_tt_kpi'].replace('0,00E+00', 0.0, inplace=True)\n",
    "\n",
    "df['thp_nom_tt_kpi'] = df['thp_nom_tt_kpi'].astype(float)\n",
    "df['thp_denom_tt_kpi'] = df['thp_denom_tt_kpi'].astype(float)\n",
    "\n",
    "# Change sector values and carrier\n",
    "df['sector'] = df['sector'].apply(lambda l: int(l[-1]))\n",
    "df['cell_name'] = df['cell_name'].apply(lambda l: int(l[-2]))\n",
    "df = df.rename(columns={'cell_name': 'carrier'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['timestamp'] = df['period_start_time'].apply(lambda l: str(l[:10]) + ' ' + str(l[11:19]))\n",
    "df['day_partition_key'] = df['day_partition_key'].astype(str)\n",
    "df['cell_hour'] = df['cell_hour'].astype(str)\n",
    "#df['cell_hour'] = df['cell_hour'].apply(lambda l: '0' + l if len(l) == 1 else l)\n",
    "\n",
    "df['timestamp'] = df['day_partition_key'] + df['cell_hour']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting data after timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['timestamp'] = pd.to_datetime(df['timestamp'], format='%Y%m%d%H')\n",
    "df = df.sort_values(by=['timestamp'])\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the resolution \n",
    "From below we see that it is hourly, and only once is there a gap of more than an hour (2020-03-29)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = df.groupby(['timestamp'])\n",
    "\n",
    "for timestamp, group in grouped_df:\n",
    "    t = timestamp\n",
    "    break\n",
    "\n",
    "for timestamp, group in grouped_df:\n",
    "    next_t = timestamp\n",
    "    td = next_t - t\n",
    "    td_mins = int(td.total_seconds() / 60)\n",
    "    if td_mins != 60:\n",
    "        print(f'Time between {t} and {timestamp} is not 1 hour, but {td_mins/60} hours.')\n",
    "    t = next_t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking number of cells that has data present for each timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the number of cells present varies a lot and flunctuates around ~100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_count = df_orig.groupby('cell_name').count()['gid']\n",
    "cell_count[cell_count > 5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "timestamps = []\n",
    "num_cells_at_time = []\n",
    "for timestamp, group in grouped_df:\n",
    "    timestamps.append(timestamp)\n",
    "    num_cells_at_time.append(len(group))\n",
    "\n",
    "num_cell_df = pd.DataFrame({'timestamp': timestamps, 'num_cells': num_cells_at_time})\n",
    "fig = px.line(num_cell_df, x=\"timestamp\", y='num_cells', title='Number of cells for each timestamp')\n",
    "fig.show()\n",
    "\n",
    "plt.boxplot(num_cells_at_time);\n",
    "plt.title('Boxplot with number of cells for each timestamp')\n",
    "plt.ylabel('# of cells')\n",
    "plt.xticks([], [])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating cells within same sector\n",
    "\n",
    "### For Hackaton data\n",
    "The cell_name is of the form 'XX_ija', where:\n",
    "\n",
    "- XX in {00,01,02,..,30} denotes the site the cell belongs to;\n",
    "- i in {1,2,3} denotes the sector the cell belongs to;\n",
    "- j in {1,2,...} denotes the carrier;\n",
    "- a in {'Z','X','Y','W','V','R','Q','P'} denotes the technology and frequency of the cell based on the table below.\n",
    "\n",
    "### For Original data\n",
    "The cell_name is of the form: '{1char}{4digits}{1char}{2chars}', where:\n",
    "\n",
    "- 1char is Area\n",
    "- 4digits is range per Area\n",
    "- 1char is System (frequency/technology)\n",
    "- 2chars: 1st digit is carrier layer, starting from 1. 2nd digit is sector, range 0-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_original_data = True\n",
    "df2 = df.copy()\n",
    "\n",
    "if not is_original_data:    \n",
    "    df2['site'] = df2['cell_name'].apply(lambda s: int(s.split('_')[0]))\n",
    "    df2['sector'] = df2['cell_name'].apply(lambda s: int(s.split('_')[1][0]))\n",
    "    df2['carrier'] = df2['cell_name'].apply(lambda s: int(s.split('_')[1][1]))\n",
    "    df2['tech'] = df2['cell_name'].apply(lambda s: s.split('_')[1][2])\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill NaNs of cells "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df = df2.copy()\n",
    "for c in nan_columns:\n",
    "    if is_numeric_dtype(agg_df[c]):\n",
    "        if c in ['thp_denom_tt_kpi', 'thp_nom_tt_kpi']:\n",
    "            agg_func = 'mean'\n",
    "        else:\n",
    "            agg_func = 'median'\n",
    "        agg_df[c] = agg_df[c].fillna(agg_df.groupby(['timestamp', 'site', 'sector', 'tech'])[c].transform(agg_func))\n",
    "        agg_df[c] = agg_df[c].fillna(agg_df.groupby(['timestamp', 'site', 'sector'])[c].transform(agg_func))\n",
    "        agg_df[c] = agg_df[c].fillna(agg_df.groupby(['timestamp', 'site'])[c].transform(agg_func))\n",
    "        agg_df[c] = agg_df[c].fillna(agg_df.groupby(['site', 'sector'])[c].transform(agg_func))\n",
    "        agg_df[c] = agg_df[c].fillna(agg_df.groupby(['site'])[c].transform(agg_func))\n",
    "        agg_df[c] = agg_df[c].fillna(agg_df[c].median())\n",
    "\n",
    "print(agg_df.isna().sum())\n",
    "agg_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now aggregate across each sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# To aggregate columns differently, pass this to the agg-function\n",
    "#aggregate_methods = {\n",
    " #   'avail_period_duration': 'mean',\n",
    "  #  'unavail_unplan_nom': 'mean',\n",
    "   # 'unavail_unplan_denom': 'mean',\n",
    "    #'unavail_total_nom': 'mean',\n",
    "    #'unavail_total_denom': 'mean',\n",
    "    #'bandwidth': 'mean'\n",
    "#}\n",
    "\n",
    "agg_df = agg_df.groupby(['timestamp', 'site', 'sector']).agg('mean').reset_index()\n",
    "# Remove irrelevant columns \n",
    "agg_df.drop(columns=['gid', 'carrier'], inplace=True)\n",
    "agg_df[(agg_df['site'] == 'J1824') & (agg_df['sector'] == 1)].head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "grouped_df = agg_df.groupby(['site', 'sector'])\n",
    "\n",
    "for (site, sector), group in grouped_df:\n",
    "    count = 0\n",
    "    group = group.sort_values(by=['timestamp'])\n",
    "    t = group.iloc[0, 0]\n",
    "    for i in range(1, group.shape[0]):\n",
    "        next_t = group.iloc[i, 0]\n",
    "        td = next_t - t\n",
    "        td_mins = int(td.total_seconds() / 60)\n",
    "        if td_mins != 60:\n",
    "            count += 1\n",
    "            # print(f'Time between {t} and {next_t} is not 1 hour, but {td_mins/60} hours.')\n",
    "        t = next_t\n",
    "    print(f'{site}-{sector} has {count} (out of {group.shape[0]}) samples with more than 1 hour from last timestamp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grouped_agg_df = agg_df.groupby(['timestamp'])\n",
    "timestamps = []\n",
    "num_sectors_at_time = []\n",
    "for timestamp, group in grouped_agg_df:\n",
    "    timestamps.append(timestamp)\n",
    "    num_sectors_at_time.append(len(group))\n",
    "\n",
    "num_sector_df = pd.DataFrame({'timestamp': timestamps, 'num_sectors': num_sectors_at_time})\n",
    "fig = px.line(num_sector_df, x=\"timestamp\", y='num_sectors', hover_data={\"timestamp\": \"|%B %d. %H:%M, %Y\"}, title='Number of sectors for each timestamp')\n",
    "fig.show()\n",
    "\n",
    "\n",
    "plt.boxplot(num_sectors_at_time);\n",
    "plt.title('Boxplot with number of sectors for each timestamp')\n",
    "plt.ylabel('# of sectors')\n",
    "plt.xticks([], [])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the number of timetamps where the sectors has data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(70, 10))\n",
    "ax = sns.countplot(x=\"site\", hue=\"sector\", data=agg_df)\n",
    "plt.legend(loc='upper right', fontsize=40)\n",
    "ax.set_ylabel('# of cells', fontsize=50)\n",
    "ax.xaxis.label.set_size(50)\n",
    "plt.xticks(fontsize=30)\n",
    "plt.yticks(fontsize=30)\n",
    "plt.title('Number of timestamp where sector has data, for each site', fontsize=70)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing sites without exactly three sectors \n",
    "agg_df = agg_df[~agg_df['site'].isin(['J2964', 'J4608', 'J5004', 'J4969', 'J8062'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(70, 10))\n",
    "ax = sns.countplot(x=\"site\", hue=\"sector\", data=agg_df)\n",
    "plt.legend(loc='upper right', fontsize=40)\n",
    "ax.set_ylabel('# of cells', fontsize=50)\n",
    "ax.xaxis.label.set_size(50)\n",
    "plt.xticks(fontsize=30)\n",
    "plt.yticks(fontsize=30)\n",
    "plt.title('Number of timestamp where sector has data, for each site', fontsize=70)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing data for one of the sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_sector(df, site, sector, column):\n",
    "    if sector is not None:\n",
    "        sector_df = df[(df['site'] == site) & (df['sector'] == sector)]\n",
    "    else:\n",
    "        sector_df = df[(df['site'] == site)]\n",
    "    fig = px.line(sector_df, x=\"timestamp\", y=column)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_sector(agg_df, 'J0847', 1, 'avail_period_duration')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating dataset \n",
    "In **agg_df**, each row corresponds to aggregated data from all cells within a sector, at a specific timestamp. However, not all sectors do have at least one active cell at all timestamps. If a sector contains no active cells for a timestamp, then a row for that sector at that timestamp does not exist. To make the resolution (every hour) and shape (there is a row for all sectors for all timestamps) consistent, we must insert rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_values = {\n",
    "    'avail_period_duration': 60, # maybe exclude\n",
    "    'unavail_unplan_nom': 0,  # maybe exclude\n",
    "    'unavail_unplan_denom': 60, # maybe exclude\n",
    "    'unavail_total_nom': 0, # maybe maybe exclude\n",
    "    'unavail_total_denom': 60,# maybe maybe exclude\n",
    "    'bandwidth': 0, # change to max of sector # maybe exclude\n",
    "    'mcdr_denom': 0, \n",
    "    'mcdr_nom_s': 0,\n",
    "    'mcdr_nom_d': 0,\n",
    "    'msdr_denom': 0, \n",
    "    'msdr_nom_s': 0,\n",
    "    'msdr_nom_d': 0,\n",
    "    'thp_denom_tt_kpi': 0, # change to max of sector\n",
    "    'thp_nom_tt_kpi': 0,\n",
    "    'ho_denom': 0,\n",
    "    'ho_nom': 0\n",
    "}\n",
    "\n",
    "# change thp, ho, msdr, mcdr to rates \n",
    "\n",
    "sector_bandwidth_max = agg_df.groupby(['site', 'sector']).agg('max')['bandwidth'].to_dict()\n",
    "sector_thp_denom_max = agg_df.groupby(['site', 'sector']).agg('max')['thp_denom_tt_kpi'].to_dict()\n",
    "# default_values_list = [default_values[c] for c in agg_df.columns[3:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_present_set = set([tuple(x) for x in agg_df[['timestamp', 'site', 'sector']].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_start = agg_df.head(1)['timestamp'].iloc[0]\n",
    "datetime_end = agg_df.tail(1)['timestamp'].iloc[0]\n",
    "\n",
    "all_timestamps = pd.date_range(datetime_start, datetime_end, freq=\"H\")\n",
    "all_sites = agg_df['site'].unique()\n",
    "all_sectors = agg_df['sector'].unique()\n",
    "\n",
    "rows_to_add = []\n",
    "for timestamp in tqdm(all_timestamps):\n",
    "    for site in all_sites:\n",
    "        for sector in all_sectors:\n",
    "            if (timestamp, site, sector) not in is_present_set:\n",
    "                bandwidth_default = sector_bandwidth_max[(site, sector)]\n",
    "                thp_default = sector_thp_denom_max[(site, sector)]\n",
    "                default_values['bandwidth'] = bandwidth_default\n",
    "                default_values['thp_denom_tt_kpi'] = thp_default\n",
    "                default_values_list = [default_values[c] for c in agg_df.columns[3:]]\n",
    "                row_insert = [timestamp, site, sector]\n",
    "                row_insert.extend(default_values_list)\n",
    "                rows_to_add.append(row_insert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_to_add_df = pd.DataFrame(rows_to_add, columns=agg_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df_filled = agg_df.append(rows_to_add_df)\n",
    "agg_df_filled = agg_df_filled.sort_values(by=['timestamp', 'site', 'sector'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(agg_df_filled.shape)\n",
    "agg_df_filled.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check that new dataframe now has constant number of sectors for each timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grouped_agg_df = agg_df_filled.groupby(['timestamp'])\n",
    "timestamps = []\n",
    "num_sectors_at_time = []\n",
    "for timestamp, group in grouped_agg_df:\n",
    "    timestamps.append(timestamp)\n",
    "    num_sectors_at_time.append(len(group))\n",
    "\n",
    "num_sector_df = pd.DataFrame({'timestamp': timestamps, 'num_sectors': num_sectors_at_time})\n",
    "fig = px.line(num_sector_df, x=\"timestamp\", y='num_sectors', hover_data={\"timestamp\": \"|%B %d. %H:%M, %Y\"}, title='Number of sectors for each timestamp')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize column again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df_filled.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cols to keep:\n",
    "cols_to_keep = ['timestamp', 'site', 'sector', 'avail_period_duration', 'unavail_unplan_nom', 'unavail_unplan_denom', 'mcdr_denom', 'msdr_denom', 'msdr_nom_s', 'msdr_nom_d', 'ho_denom', 'ho_nom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "visualize_sector(agg_df, 'J0847', 1, 'avail_period_duration')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Sectors Into the Final Dataset\n",
    "## Alternative 1: \n",
    "Group the data to get a series of graph signals with shape: (# of timestamps, # of sectors, # of features), see figure below: <img src=\"https://i.imgur.com/1izToWi.png\" width=750 height=750 />."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_metadata(df, path):\n",
    "    metadata = {\n",
    "    'start': str(df.head(1)['timestamp'].iloc[0]),\n",
    "    'end': str(df.tail(1)['timestamp'].iloc[0]),\n",
    "    'resolution_minutes': (df.iloc[1, 0] - df.iloc[0, 0]).seconds / 60,\n",
    "    'columns': df.columns.tolist()}\n",
    "    \n",
    "    with open(path, 'w') as file:\n",
    "        json.dump(metadata, file, indent=2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Sector-wise\n",
    "grouped_agg_df = agg_df_filled.groupby(['site', 'sector'])\n",
    "save_path = '../datasets/telenor/sector_data'\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "for (site, sector), group in grouped_agg_df:\n",
    "    np.save(f'{save_path}/{site}-{sector}.npy', group.values)\n",
    "\n",
    "print(group.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grouped_agg_df = agg_df_filled.groupby(['timestamp'])\n",
    "graph_signals = []\n",
    "\n",
    "for timestamp, group in tqdm(grouped_agg_df):\n",
    "    graph_signals.append(group)\n",
    "\n",
    "graph_signals = np.array(graph_signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metadata)\n",
    "print(graph_signals.shape)\n",
    "save = False\n",
    "save_path = '../datasets/telenor/'\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "if save:\n",
    "    save_metadata(agg_df_filled, f'{save_path}/graph_signals_metadata.txt') \n",
    "    np.save(f'{save_path}/graph_signals.npy', graph_signals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative 2: \n",
    "'Augment' each sector with the sectors of the same site. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(agg_df_filled.shape)\n",
    "agg_df_filled.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce number of cols\n",
    "agg_df_filled = agg_df_filled[cols_to_keep]\n",
    "agg_df_filled.columns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Reduce number of columns\n",
    "reduce_cols = False\n",
    "if reduce_cols:\n",
    "    agg_df_filled['unavail_unplan_rate'] = agg_df_filled['unavail_unplan_nom'] / agg_df_filled['unavail_unplan_denom']\n",
    "    agg_df_filled['mcdr_drate'] = agg_df_filled['mcdr_nom_d'] / (1 + agg_df_filled['mcdr_denom'])\n",
    "    agg_df_filled['mcdr_srate'] = agg_df_filled['mcdr_nom_s'] / (1 + agg_df_filled['mcdr_denom'])\n",
    "    \n",
    "    agg_df_filled['msdr_drate'] = agg_df_filled['msdr_nom_d'] / (1 + agg_df_filled['msdr_denom'])\n",
    "    agg_df_filled['msdr_srate'] = agg_df_filled['msdr_nom_s'] / (1 + agg_df_filled['msdr_denom'])\n",
    "    \n",
    "    agg_df_filled['thp_rate'] = agg_df_filled['thp_nom_tt_kpi'] / (1 + agg_df_filled['thp_denom_tt_kpi'])\n",
    "    agg_df_filled['ho_rate'] = agg_df_filled['ho_nom'] / (1 + agg_df_filled['ho_denom'])\n",
    "    \n",
    "    agg_df_filled = agg_df_filled.drop(columns=['avail_period_duration',\n",
    "           'unavail_unplan_nom', 'unavail_unplan_denom', 'unavail_total_nom',\n",
    "           'unavail_total_denom', 'bandwidth', 'mcdr_denom', 'mcdr_nom_s', 'mcdr_nom_d', \n",
    "            'msdr_denom', 'msdr_nom_s', 'msdr_nom_d','thp_denom_tt_kpi', 'thp_nom_tt_kpi', 'ho_denom', 'ho_nom'])\n",
    "    \n",
    "    # Dividing by zero gives nan, just fill in with zeros\n",
    "    agg_df_filled.fillna(0.0, inplace=True)\n",
    "    \n",
    "    agg_df_filled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_grouped = agg_df_filled.groupby(['site', 'timestamp'])\n",
    "sectors_df = []\n",
    "\n",
    "for (site, timestamp), group in tqdm(site_grouped):\n",
    "    # Merge the three sectors\n",
    "    group = group.drop(columns=['sector'])\n",
    "    s1, s2, s3 = group.iloc[0, :], group.iloc[1, :], group.iloc[2, :]\n",
    "\n",
    "    sectors_comb = {}\n",
    "    sectors_comb['timestamp'] =  str(timestamp)\n",
    "    sectors_comb['site'] = site\n",
    "\n",
    "    for i, s in enumerate([s1, s2, s3], start=1):\n",
    "        for c in group.columns[2:]:\n",
    "            sectors_comb[f'{c}_{i}'] = s[c]\n",
    "    \n",
    "    sectors_df.append(sectors_comb)\n",
    "\n",
    "sectors_df = pd.DataFrame(sectors_df, index=range(len(sectors_df)))\n",
    "sectors_df['timestamp'] = pd.to_datetime(sectors_df['timestamp'])\n",
    "sectors_df = sectors_df.sort_values(by=['site', 'timestamp'])\n",
    "display(sectors_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_sector(sectors_df, 'J0847', None, 'mcdr_denom_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sectors_df.shape)\n",
    "save = True\n",
    "save_path = '../datasets/telenor/site_data/'\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "if save:\n",
    "    save_metadata(sectors_df, f'{save_path}/metadata.txt') \n",
    "    grouped_sectors_df = sectors_df.groupby('site')\n",
    "    for site, group in grouped_sectors_df:\n",
    "        np.save(f'{save_path}/{site}.npy', group.values)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "save_data = False\n",
    "if save_data:\n",
    "    train_folder = '../datasets/telenor/train'\n",
    "    test_folder = '../datasets/telenor/test'\n",
    "    os.makedirs(train_folder, exist_ok=True)\n",
    "    os.makedirs(test_folder, exist_ok=True)\n",
    "\n",
    "    labeled_anomalies = {'chan_id': [],\n",
    "                         'anomaly_sequences': [],\n",
    "                         'class': [],\n",
    "                         'num_values': []}\n",
    "\n",
    "    site_sector_combinations = agg_df[['site', 'sector']].value_counts().index.tolist()\n",
    "    for site, sector in sorted(site_sector_combinations):\n",
    "        train, test = get_sector_data(agg_df, site, sector, test_split=0.3)\n",
    "        np.save(f'{train_folder}/{site}-{sector}.npy', train)\n",
    "        np.save(f'{test_folder}/{site}-{sector}.npy', test)\n",
    "\n",
    "        labeled_anomalies['chan_id'].append(f'{site}-{sector}')\n",
    "        labeled_anomalies['anomaly_sequences'].append([])\n",
    "        labeled_anomalies['class'].append('')\n",
    "        labeled_anomalies['num_values'].append(test.shape[0])\n",
    "\n",
    "    labeled_anomalies_df = pd.DataFrame(labeled_anomalies)\n",
    "    labeled_anomalies_df.to_csv('../datasets/telenor/labeled_anomalies.csv')\n",
    "    \n",
    "    train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
