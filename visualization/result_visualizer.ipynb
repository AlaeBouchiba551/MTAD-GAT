{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result Visualizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different visualizations of anomaly detection result, including forecasts, reconstructions, anomaly scores, predicted and actual anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import plotly as py\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode\n",
    "import plotly.graph_objs as go\n",
    "import cufflinks as cf\n",
    "import glob\n",
    "import sys\n",
    "import json\n",
    "cf.go_offline()\n",
    "init_notebook_mode\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "from plotting import Plotter\n",
    "\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify data result to visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_path = '../output/MSL'\n",
    "#output_path = '../output/SMAP'\n",
    "#output_path = '../output/TELENOR/J0858/26042021_201345'\n",
    "output_path = '../output/TELENOR/J0858/26042021_201345'\n",
    "\n",
    "#output_path = '../output/SMD/1-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotter = Plotter(output_path)\n",
    "plotter.result_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive plot \n",
    "- Forecasted value, reconstructed value and actual value for one channel (feature) are plotted in the first plot. You can also specify start and end to limit the x-axis.\n",
    "- Time steps with actual (true) anomalies are visualized by a light red rectangel, while predicted anomalies by a light blue rectangel. If anomalies are predicted correctly the color of the rectangle will therefore be purple. \n",
    "- In the second plot the anomaly score (error) is visualized, together with the threshold used to predict anomalies. To toggle between the error of the channel and the total error for all channels, use ```show_tot_err```. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# r = \"4872-4875\"\n",
    "# start, end = int(r.split('-')[0])-200, int(r.split('-')[1])+100\n",
    "\n",
    "start, end = None, None\n",
    "plotter.plot_channel(channel=5, show_tot_err=True, start=start, end=end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot forecasts, reconstructions, true values, anomaly scores, prediction and actual anomalies for all channels in a compact way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plotter.plot_all_channels(start=None, end=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare errors with true anomalies for single or all channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter.plot_errors(channel='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with other thresholding methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting some of the evaluation methods here, in order to evaluate with new threshold methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_point2point(predict, actual):\n",
    "    \"\"\"\n",
    "    calculate f1 score by predict and actual.\n",
    "    Args:\n",
    "            predict (np.ndarray): the predict label\n",
    "            actual (np.ndarray): np.ndarray\n",
    "    \"\"\"\n",
    "    TP = np.sum(predict * actual)\n",
    "    TN = np.sum((1 - predict) * (1 - actual))\n",
    "    FP = np.sum(predict * (1 - actual))\n",
    "    FN = np.sum((1 - predict) * actual)\n",
    "    precision = TP / (TP + FP + 0.00001)\n",
    "    recall = TP / (TP + FN + 0.00001)\n",
    "    f1 = 2 * precision * recall / (precision + recall + 0.00001)\n",
    "    return f1, precision, recall, TP, TN, FP, FN\n",
    "\n",
    "def adjust_predicts(score, label, threshold, advance=1, pred=None, calc_latency=False):\n",
    "    \"\"\"\n",
    "    Calculate adjusted predict labels using given `score`, `threshold` (or given `pred`) and `label`.\n",
    "    Args:\n",
    "            score (np.ndarray): The anomaly score\n",
    "            label (np.ndarray): The ground-truth label\n",
    "            threshold (float): The threshold of anomaly score.\n",
    "                    A point is labeled as \"anomaly\" if its score is lower than the threshold.\n",
    "            pred (np.ndarray or None): if not None, adjust `pred` and ignore `score` and `threshold`,\n",
    "            calc_latency (bool):\n",
    "    Returns:\n",
    "            np.ndarray: predict labels\n",
    "    \"\"\"\n",
    "    if len(score) != len(label):\n",
    "        raise ValueError(\"score and label must have the same length\")\n",
    "    score = np.asarray(score)\n",
    "    label = np.asarray(label)\n",
    "    if pred is None:\n",
    "        predict = score > threshold\n",
    "    else:\n",
    "        predict = pred\n",
    "\n",
    "    actual = label > 0.1\n",
    "    anomaly_state = False\n",
    "    anomaly_count = 0\n",
    "    latency = 0\n",
    "\n",
    "    # Added advance in case model predicts anomaly 'in advance' within a small window\n",
    "    # Advance should be 0 or small\n",
    "    for i in range(len(score)):\n",
    "        if any(actual[max(i - advance, 0) : i + 1]) and predict[i] and not anomaly_state:\n",
    "            anomaly_state = True\n",
    "            anomaly_count += 1\n",
    "            for j in range(i, 0, -1):\n",
    "                if not actual[j]:\n",
    "                    break\n",
    "                else:\n",
    "                    if not predict[j]:\n",
    "                        predict[j] = True\n",
    "                        latency += 1\n",
    "        elif not actual[i]:\n",
    "            anomaly_state = False\n",
    "        if anomaly_state:\n",
    "            predict[i] = True\n",
    "    if calc_latency:\n",
    "        return predict, latency / (anomaly_count + 1e-4)\n",
    "    else:\n",
    "        return predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First load which data to try other thresholding methods for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import more_itertools as mit\n",
    "\n",
    "#data_name = \"SMD/1-1\"\n",
    "#data_name = 'MSL'\n",
    "#data_name = 'SMAP'\n",
    "#data_name = 'TELENOR/J0847/21042021_232131'\n",
    "data_name = 'TELENOR/J0858/26042021_201345'\n",
    "\n",
    "output_path = f'../output/{data_name}'\n",
    "plotter = Plotter(output_path)\n",
    "plotter.result_summary()\n",
    "df = plotter.data\n",
    "true_anom = df['True_Anomaly'].values\n",
    "train_scores = np.load(f'{output_path}/train_scores.npy')\n",
    "test_scores = np.load(f'{output_path}/test_scores.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For MSL or SMAP\n",
    "This next cell is not necessary for the SMD dataset or TELENOR.\n",
    "For MSL, SMAP the time series for different channels are concatinated.\n",
    "Each has a file called *labeled_anomalies.csv* that holds information about how long the sequences for each channel is (SMAP and MSL shares this file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if data_name in ['SMAP', 'MSL']:\n",
    "    md = pd.read_csv('../datasets/data/labeled_anomalies.csv')\n",
    "    # If SMAP or MSL, only keep channels belonging to that dataset:\n",
    "    # Also, P-2 is not included for some reason\n",
    "    if 'spacecraft' in md.columns:\n",
    "        md = md[md['spacecraft'] == data_name]\n",
    "        md = md[md['chan_id'] != 'P-2']\n",
    "\n",
    "    # Sort values by channel\n",
    "    md = md.sort_values(by=['chan_id'])\n",
    "    display(md.head())\n",
    "\n",
    "    # Getting the cumulative start index for each channel\n",
    "    sep_cuma = np.cumsum(md['num_values'].values) - 100\n",
    "    sep_cuma = sep_cuma[:-1]\n",
    "\n",
    "    # Remove errors for time steps when transition to new channel (as this will be impossible for model to predict)\n",
    "    buffer = np.arange(1, 5)\n",
    "    i_remov = np.sort(np.concatenate((sep_cuma, np.array([i+buffer for i in sep_cuma]).flatten(),\n",
    "                                    np.array([i-buffer for i in sep_cuma]).flatten())))\n",
    "    i_remov = i_remov[(i_remov < len(test_scores)) & (i_remov >= 0)]\n",
    "    i_remov = np.sort(np.unique(i_remov))\n",
    "    if len(i_remov) != 0:\n",
    "        test_scores[i_remov] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold method from Telemanom\n",
    "This method is the one used in [Detecting Spacecraft Anomalies Using LSTMs and Nonparametric Dynamic Thresholding](https://arxiv.org/pdf/1802.04431.pdf).\n",
    "\n",
    "In simple terms, a threshold is found that, if all values above are removed, would cause the greatest percent decrease in the mean and standard deviation of the smoothed errors es . The function also penalizes for having larger numbers of anomalous values and sequences to prevent overly greedy behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One threshold: For data where channels are not concatinated \n",
    "This concerns SMD. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_epsilon(errors):\n",
    "    e_s = errors\n",
    "\n",
    "    sd_threshold = None\n",
    "    best_epsilon = None \n",
    "\n",
    "    max_score = -10000000\n",
    "    mean_e_s = np.mean(e_s)\n",
    "    sd_e_s = np.std(e_s)\n",
    "\n",
    "    for z in np.arange(2.5, 12, 0.5):\n",
    "        epsilon = mean_e_s + sd_e_s * z\n",
    "        pruned_e_s = e_s[e_s < epsilon]\n",
    "\n",
    "        i_anom = np.argwhere(e_s >= epsilon).reshape(-1,)\n",
    "        buffer = np.arange(1, 50)\n",
    "        i_anom = np.sort(np.concatenate((i_anom,\n",
    "                                        np.array([i+buffer for i in i_anom])\n",
    "                                         .flatten(),\n",
    "                                        np.array([i-buffer for i in i_anom])\n",
    "                                         .flatten())))\n",
    "        i_anom = i_anom[(i_anom < len(e_s)) & (i_anom >= 0)]\n",
    "        i_anom = np.sort(np.unique(i_anom))\n",
    "\n",
    "        if len(i_anom) > 0:\n",
    "            groups = [list(group) for group in mit.consecutive_groups(i_anom)]\n",
    "            E_seq = [(g[0], g[-1]) for g in groups if not g[0] == g[-1]]\n",
    "\n",
    "\n",
    "            mean_perc_decrease = (mean_e_s - np.mean(pruned_e_s)) / mean_e_s\n",
    "            sd_perc_decrease = (sd_e_s - np.std(pruned_e_s)) / sd_e_s\n",
    "            score = (mean_perc_decrease + sd_perc_decrease) #/ (len(E_seq) ** 2 + len(i_anom))\n",
    "\n",
    "            # sanity checks / guardrails\n",
    "            if score >= max_score and len(i_anom) < (len(e_s) * 0.5):\n",
    "                max_score = score\n",
    "                sd_threshold = z\n",
    "                best_epsilon = epsilon\n",
    "                \n",
    "    return best_epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Multiple thresholds: For data with concatinated channels  \n",
    "In order to properly evaluate the data that consists of concatinations of time series of multiple channels, this next method should be used. It is the exact same method as above, only that a separate threshold is found for each channel.\n",
    "This is for MSL, SMAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_epsilon_multiple_channels(test_scores):\n",
    "\n",
    "    sep_cuma = np.cumsum(md['num_values'].values) - 100\n",
    "    epsilons = []\n",
    "    s = [0] + sep_cuma.tolist()\n",
    "    for c_start, c_end in [(s[i], s[i+1]) for i in range(len(s)-1)]:\n",
    "        best_epsilon = None \n",
    "        max_score = -10000000\n",
    "        e_s = test_scores[c_start: c_end+1]\n",
    "        mean_e_s = np.mean(e_s)\n",
    "        sd_e_s = np.std(e_s)\n",
    "\n",
    "        for z in np.arange(2.5, 12, 0.5):\n",
    "            epsilon = mean_e_s + sd_e_s * z\n",
    "            pruned_e_s = e_s[e_s < epsilon]\n",
    "\n",
    "            i_anom = np.argwhere(e_s >= epsilon).reshape(-1,)\n",
    "            buffer = np.arange(1, 50)\n",
    "            i_anom = np.sort(np.concatenate((i_anom,\n",
    "                                            np.array([i+buffer for i in i_anom])\n",
    "                                             .flatten(),\n",
    "                                            np.array([i-buffer for i in i_anom])\n",
    "                                             .flatten())))\n",
    "            i_anom = i_anom[(i_anom < len(e_s)) & (i_anom >= 0)]\n",
    "            i_anom = np.sort(np.unique(i_anom))\n",
    "\n",
    "            if len(i_anom) > 0:\n",
    "                groups = [list(group) for group in mit.consecutive_groups(i_anom)]\n",
    "                E_seq = [(g[0], g[-1]) for g in groups if not g[0] == g[-1]]\n",
    "\n",
    "\n",
    "                mean_perc_decrease = (mean_e_s - np.mean(pruned_e_s)) / mean_e_s\n",
    "                sd_perc_decrease = (sd_e_s - np.std(pruned_e_s)) / sd_e_s\n",
    "                score = (mean_perc_decrease + sd_perc_decrease) / 0.5*(len(E_seq) ** 2 + len(i_anom))\n",
    "\n",
    "                # sanity checks / guardrails\n",
    "                if score >= max_score and len(i_anom) < (len(e_s) * 0.5):\n",
    "                    max_score = score\n",
    "                    best_epsilon = epsilon\n",
    "\n",
    "        epsilons.extend([best_epsilon]*(c_end - c_start))\n",
    "        \n",
    "    return epsilons\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating predicted anomalies using the new threshold method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, figsize=(30, 10), sharex=True, )\n",
    "\n",
    "# For SMD, TELENOR\n",
    "if 'SMD' in data_name or data_name.startswith('TELENOR'):\n",
    "    best_epsilon = find_epsilon(test_scores)\n",
    "    print(f'Best threshold found: {best_epsilon}\\n')\n",
    "    if data_name.startswith('TELENOR'):\n",
    "        pred_anom_adjusted = [0]*len(test_scores)\n",
    "        f1, precision, recall, TP, TN, FP, FN = None, None, None, None, None, None, None\n",
    "    else:\n",
    "        pred_anom_adjusted = adjust_predicts(test_scores, true_anom, best_epsilon)\n",
    "        f1, precision, recall, TP, TN, FP, FN = calc_point2point(pred_anom_adjusted, true_anom)\n",
    "    epsilons = [best_epsilon for i in range(len(test_scores))]\n",
    "\n",
    "# For MSL, SMAP\n",
    "else:\n",
    "    epsilons = find_epsilon_multiple_channels(test_scores)\n",
    "    pred_anom_adjusted = adjust_predicts(test_scores, true_anom, epsilons)\n",
    "    f1, precision, recall, TP, TN, FP, FN = calc_point2point(pred_anom_adjusted, true_anom)\n",
    "        \n",
    "    if data_name == 'MSL':\n",
    "        axs[0].set_ylim([0, 5])\n",
    "\n",
    "        \n",
    "\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1: {f1}')\n",
    "\n",
    "axs[0].plot(test_scores, c='r', label='anomaly scores')\n",
    "axs[0].plot(epsilons, linestyle='dashed', c='black', label='threshold')\n",
    "axs[1].plot(pred_anom_adjusted, label='predicted anomalies', alpha=0.7)\n",
    "axs[1].plot(true_anom, label='actual anomalies', alpha=0.7)\n",
    "fig.legend(prop={'size': 20})\n",
    "plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "## Interactive plot with the next threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plotter.data['Pred_Anomaly'] = pred_anom_adjusted\n",
    "plotter.data['threshold'] = epsilons\n",
    "plotter.data['Pred_Anomaly'] = pred_anom_adjusted\n",
    "plotter.data['Tot_A_Score'] = test_scores\n",
    "\n",
    "start, end = None, None\n",
    "plotter.plot_channel(channel=2, show_tot_err=False, start=start, end=end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method to get results from all subparts of SMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate results for all subparts of dataset \n",
    "result_dir = '../output/SMD'\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "\n",
    "for folder in os.listdir(result_dir):\n",
    "    path = f'{result_dir}/{folder}/summary.txt'\n",
    "    if not os.path.exists(path):\n",
    "        print(f'Folder {folder} does not has a summary.txt file')\n",
    "        continue\n",
    "    with open(path) as f:\n",
    "        result_dict = json.load(f)['pot_result']\n",
    "        if result_dict['f1'] < 0.3:\n",
    "            print(path)\n",
    "        precisions.append(result_dict['precision'])\n",
    "        recalls.append(result_dict['recall'])\n",
    "        f1s.append(result_dict['f1'])\n",
    "print('-- Done')\n",
    "\n",
    "precisions = np.array(precisions)\n",
    "recalls = np.array(recalls)\n",
    "f1s = np.array(f1s)\n",
    "\n",
    "print(f'Avg precision: {precisions.mean():.4f}')\n",
    "print(f'Avg recall: {recalls.mean():.4f}')\n",
    "print(f'Avg f1: {f1s.mean():.4f}')\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(20, 5))\n",
    "axs[0].set_title('Precisions')\n",
    "axs[0].boxplot(precisions);\n",
    "axs[1].set_title('Recalls')\n",
    "axs[1].boxplot(recalls);\n",
    "axs[2].set_title('F1s')\n",
    "axs[2].boxplot(f1s);\n",
    "plt.show();\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(20, 5))\n",
    "axs[0].hist(precisions, bins=len(precisions));\n",
    "axs[1].hist(recalls, bins=len(recalls));\n",
    "axs[2].hist(f1s, bins=len(f1s));\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
